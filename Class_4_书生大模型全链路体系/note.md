# 书生·浦语大模型全链路开源体系（学习笔记）

## 1、背景：专用模型到通用大模型
1. 专用模型：针对特定任务，一个模型解决一个问题
2. 通用大模型：一个模型对应多个任务、多种模态

## 2、书生·浦语大模型
### 2.1 开源历程
- 2023.6.7: InternLM 千亿参数语言大模型发布
- 2023.7.6: InternLM 千亿参数大模型全面升级
- 2023.8.14: 书生·万卷 1.0 多模态预训练语料库开源
- 2023.8.21: 升级版对话模型 InternLM-Chat-7B v1.1 发布，开源智能体框架 Lagent
- 2023.8.28: InternLM 千亿参数模型参数量升级至 123B
- 2023.9.20: 增强版 InternLM-208 开源，开源工具链全线升级
- 2024.1.17: InternLM2 开源
![](./pics/1.png)

### 2.2 InternLM2 体系
不同参数量的模型应用于不同场景：
- 7B: 轻量级应用
- 20B:支持更加复杂的使用场景
 
每个参数量级的模型包含3种架构：
- **InternLM2-Base**: 高质量基座模型
- **InternLM**: 在通用语言能力基础上，强化了多个方向的能力
- **InternLM2-Chat**: 在Base基础上，经过了SFT和RLHF，面向对话交互进行了优化，具有很好的指令遵循、共情聊天和调用工具等能力。

### 2.3 InternLM2的改进点
**根本： 回归语言建模的本质**
- **多维度数据价值评估**：基于文本质量、信息质量、信息密度等维度对数据价值进行综合评估与提升
- **高质量语料驱动的数据富集**：利用高质量语料的特征从物理世界、互联网以及语料库中进一步富集更多类似语料
- **有针对性的数据补齐**：针对性补充语料，重点加强世界知识、数理、代码等核心能力
![](./pics/2.png)

### 2.4 InternLM2 主要亮点
- 超长上下文
- 综合性能全面提升
- 优秀的对话和创作体验
- 工具调用能力
- 内生的数理能力和数据分析工具
![](./pics/3.png)

### 2.5 InternLM2 从模型到应用
#### 2.5.1 典型流程
- 业务场景是否复杂？->是否需要去微调模型？
- 算力够吗？->全参数微调还是部分参数微调？
- 是否需要环境交互？->是否需要智能体？
![](./pics/4.png)

### 2.6 书生·浦语全链条开源开放体系
#### 2.6.1 **数据-书生·万卷**
![](./pics/5.png)
#### 2.6.2 **预训练-InternLM-Train**
![](./pics/6.png)
#### 2.6.3 **微调-XTuner**
- 增量续训：学习新知识，如某个垂类领域知识
- 有监督微调：让模型学会理解各种指令进行对话，或学习少量领域知识
![](./pics/7.png)
![](./pics/8.png)
#### 2.6.4 **部署-LMDeploy**
![](./pics/15.png)
##### (a) **LMDeploy vs. vLLM**
![](./pics/16.png)
#### 2.6.5 **评测-OpenCompass**
![](./pics/9.png)
##### (a) **CompassRank: 中立全面的性能榜单**
![](./pics/10.png)
##### (b) **CompassKit: 大模型评测全栈工具链**
![](./pics/11.png)
##### (c) **CompassHub: 高质量评测基准社区**
![](./pics/12.png)
##### (d-1) **CompassHub 年度榜单（综合性客观评测）**
- **整体能力仍有较大提升空间**：采用了更加准确的循环评测策略，实现了对模型真实能力的分析。在百分制的客观评测基准中，GPT-4-Turbo 仅仅达到了 61.8 分的及格水平
- **理科能力和模型尺寸关联性高**：在语言和知识这类“文科”维度，中轻量级模型和重量级/闭源商业模型差距较小，但在数学、推理、代码等维度上，性能和尺寸呈现较强相关性
- **复杂推理仍是短板**：国内多个模型综合能力接近 GPT-4-Turbo，但在复杂推理上仍然存在较大差距，并且和模型尺寸存在较强相关性
- **模型主客观性能需综合参考**：大量开源模型和 API 模型的客观性能和主观性能存在较大偏差，社区不仅仅需要夯实客观能力基础，更需要在偏好对齐和对话体验上下功夫
![](./pics/13.png)
##### (d-2) **CompassHub 年度榜单（主观评测-对战胜率）**
- **闭源大模型接近 GPT-4 水平**：国内近期发布的部分大模型表现优异，多个维度上缩小了与 GPT-4-Turbo 的差距
- **国内模型在中文场景具有性能优势**：在中文语言理解、中文知识和中文创作上，国内商业模型相比 GPT-4-Turbo 具有极强的竞争力，甚至部分模型实现了单个维度上对 GPT-4-Turbo 的超越
- **开源社区未来可期**：Yi-34B-Chat、InternLM2-Chat-20B 以中轻量级的尺寸，展示出优秀的综合性对话体验，并接近商业闭源模型的性能
![](./pics/14.png)
#### 2.6.6 **应用-Lagent & AgentLego**
##### (a) **轻量级智能体框架 Lagent**
- 支持多种类型的智能体能力
- 灵活支持多种大模型
- 简单易拓展，支持丰富的工具
![](./pics/17.png)
##### (b) **多模态智能体工具箱 AgentLego**
![](./pics/18.png)